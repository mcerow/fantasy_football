{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 -- Data Collection\n",
    "\n",
    "This notebook contains the functions to scrape offensive player stats, week and total fantasy points for players & the defense for a team, and the defense stats. It initializes the dataframes the observations will be added to. I set up the url functions to update with the week number that will need to be manually updated (see below).\n",
    "\n",
    "I first import all necessary libraries and set my dataframe formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import tnrange\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.1f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Week Number\n",
    "\n",
    "week_no needs to be updated for the week just ended in the football season. This will update url functions and the dataframe for the week over week fantasy points dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_no = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrames\n",
    "\n",
    "#### Offense\n",
    "\n",
    "This dataframe will be used for the offensive player stats on the season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['Player', 'Team', 'Position', 'Age', 'Games', 'GamesStarted', 'CompletedPasses', \n",
    "                             'PassesAttempted', 'PassingYds', 'PassingTDs', 'Interceptions', 'RushingAttempts', \n",
    "                             'RushingYds', 'RushingYdspAtt', 'RushingTDs', 'Targeted', 'Receptions', \n",
    "                             'ReceivingYds', 'YdspReception', 'ReceivingTDs', 'Fumbles', 'LostFumbles', 'TtlTDs', \n",
    "                             'TwoPTConversions', 'TwoPTConversionPasses', 'FDFantasyPts', 'PositionRank', \n",
    "                             'OverallRank'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fantasy Points\n",
    "\n",
    "These dataframes will be used when scraping the player/team fantasy points. There is one for total points and one for the week. The week column will update when the week_no variable is updated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_fantasy = pd.DataFrame(columns = ['Player', 'Team', 'Position', 'Week_' + str(week_no)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekTTL_fantasy = pd.DataFrame(columns = ['Player', 'Team', 'Position', 'TTL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defense\n",
    "\n",
    "This dataframe will be used to collect a team's defensive stats as a total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "defense_df = pd.DataFrame(columns = ['Team', 'Ttl_Pts_Allowed', 'Ttl_Offense_Plays_Allowed', 'Yds_p_Play', 'Ttl_Yds', \n",
    "                                    'Rushing_Att', 'Rushing_Yds', 'Rushing_Yds_p_Att', 'Rushing_TDs', 'Passing_Att',\n",
    "                                    'Passing_Yds_p_Att', 'Completions', 'Yds_p_Completion', 'Passing_Yds', \n",
    "                                     'Passing_TDs', 'RZ_Att', 'RZ_TD', 'RZ_Percent', 'Ttl_Turnovers', 'Interceptions',\n",
    "                                    'Fumbles', 'Sacks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_offense(url):\n",
    "    \"\"\"\n",
    "    This function takes a url and passes it through requests.get and then uses BeautifulSoup to parse the html for \n",
    "    stats by player.\n",
    "    \n",
    "    Parameters:\n",
    "        url: website looking to scrape for information.\n",
    "        \n",
    "    Returns:\n",
    "        Completed dataframe with offensive player stats season to date in the NFL.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.content, 'html.parser')\n",
    "    container = soup.find('tbody')\n",
    "    \n",
    "    for i in tqdm(range(len(container.findAll('td', {'data-stat': 'player'})))):\n",
    "        name = container.findAll('td', {'data-stat': 'player'})[i].get_text().rstrip(' ')\n",
    "        team = container.findAll('td', {'data-stat': 'team'})[i].get_text()\n",
    "        position = container.findAll('td', {'data-stat': 'fantasy_pos'})[i].get_text()\n",
    "        age = container.findAll('td', {'data-stat': 'age'})[i].get_text()\n",
    "        games = container.findAll('td', {'data-stat': 'g'})[i].get_text()\n",
    "        gamesstarted = container.findAll('td', {'data-stat': 'gs'})[i].get_text()\n",
    "        completions = container.findAll('td', {'data-stat': 'pass_cmp'})[i].get_text()\n",
    "        pass_att = container.findAll('td', {'data-stat': 'pass_att'})[i].get_text()\n",
    "        pass_yds = container.findAll('td', {'data-stat': 'pass_yds'})[i].get_text()\n",
    "        pass_tds = container.findAll('td', {'data-stat': 'pass_td'})[i].get_text()\n",
    "        pass_int = container.findAll('td', {'data-stat': 'pass_int'})[i].get_text()\n",
    "        rush_att = container.findAll('td', {'data-stat': 'rush_att'})[i].get_text()\n",
    "        rush_yds = container.findAll('td', {'data-stat': 'rush_yds'})[i].get_text()\n",
    "        yds_p_att = container.findAll('td', {'data-stat': 'rush_yds_per_att'})[i].get_text()\n",
    "        rushing_td = container.findAll('td', {'data-stat': 'rush_td'})[i].get_text()\n",
    "        targets = container.findAll('td', {'data-stat': 'targets'})[i].get_text()\n",
    "        receptions = container.findAll('td', {'data-stat': 'rec'})[i].get_text()\n",
    "        rec_yds = container.findAll('td', {'data-stat': 'rec_yds'})[i].get_text()\n",
    "        rec_yds_rec = container.findAll('td', {'data-stat': 'rec_yds_per_rec'})[i].get_text()\n",
    "        rec_td = container.findAll('td', {'data-stat': 'rec_td'})[i].get_text()\n",
    "        fumbles = container.findAll('td', {'data-stat': 'fumbles'})[i].get_text()\n",
    "        lost_fum = container.findAll('td', {'data-stat': 'fumbles_lost'})[i].get_text()\n",
    "        ttl_td = container.findAll('td', {'data-stat': 'all_td'})[i].get_text()\n",
    "        twopt_conv = container.findAll('td', {'data-stat': 'two_pt_md'})[i].get_text()\n",
    "        twopt_pass = container.findAll('td', {'data-stat': 'two_pt_pass'})[i].get_text()\n",
    "        fant_pts = container.findAll('td', {'data-stat': 'fanduel_points'})[i].get_text()\n",
    "        pos_rank = container.findAll('td', {'data-stat': 'fantasy_rank_pos'})[i].get_text()\n",
    "        overall_rank = container.findAll('td', {'data-stat': 'fantasy_rank_overall'})[i].get_text()\n",
    "        \n",
    "        global df\n",
    "        \n",
    "        df = df.append({'Player': name, \n",
    "                       'Team': team,\n",
    "                       'Position': position,\n",
    "                       'Age': age,\n",
    "                       'Games': games,\n",
    "                       'GamesStarted': gamesstarted,\n",
    "                       'CompletedPasses': completions,\n",
    "                       'PassesAttempted': pass_att,\n",
    "                       'PassingYds': pass_yds,\n",
    "                       'PassingTDs': pass_tds,\n",
    "                       'Interceptions': pass_int,\n",
    "                       'RushingAttempts': rush_att,\n",
    "                       'RushingYds': rush_yds,\n",
    "                       'RushingYdspAtt': yds_p_att,\n",
    "                       'RushingTDs': rushing_td,\n",
    "                       'Targeted': targets,\n",
    "                       'Receptions': receptions,\n",
    "                       'ReceivingYds': rec_yds,\n",
    "                       'YdspReception': rec_yds_rec,\n",
    "                       'ReceivingTDs': rec_td,\n",
    "                       'Fumbles': fumbles,\n",
    "                       'LostFumbles': lost_fum,\n",
    "                       'TtlTDs': ttl_td,\n",
    "                       'TwoPTConversions': twopt_conv,\n",
    "                       'TwoPTConversionPasses': twopt_pass,\n",
    "                       'FDFantasyPts': fant_pts,\n",
    "                       'PositionRank': pos_rank,\n",
    "                       'OverallRank': overall_rank}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### week fantasy points\n",
    "\n",
    "def get_lw_fantasy(url):\n",
    "    \"\"\"\n",
    "    This function takes a url and passes it through requests.get and then uses BeautifulSoup to parse the html for \n",
    "    fantasy points by player and team when it comes to the defense.\n",
    "    \n",
    "    Parameters:\n",
    "        url: website looking to scrape for information.\n",
    "        \n",
    "    Returns:\n",
    "        Lists for names, teams, positions and week fantasy points that can be set equal to the columns for a \n",
    "        dataframe.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.content, 'html.parser')\n",
    "    container = soup.find('tbody')\n",
    "    \n",
    "    names = []\n",
    "    teams = []\n",
    "    positions = []\n",
    "    week_1 = []\n",
    "    \n",
    "    team_count = 1\n",
    "    pos_count = 2\n",
    "    fant_pts = 3\n",
    "    \n",
    "    for i in range(len(container.findAll('td', class_ = 'player-label'))):\n",
    "        name = container.findAll('td', class_ = 'player-label')[i].get_text()\n",
    "        names.append(name)\n",
    "        \n",
    "    for i in range(len(container.findAll('td', class_ = 'center'))):\n",
    "        if team_count <= len(container.findAll('td', class_ = 'center')):\n",
    "            team = container.findAll('td', class_ = 'center')[team_count].get_text()\n",
    "            teams.append(team)\n",
    "            team_count += 6\n",
    "        \n",
    "        if pos_count <= len(container.findAll('td', class_ = 'center')):\n",
    "            position = container.findAll('td', class_ = 'center')[pos_count].get_text()\n",
    "            positions.append(position)\n",
    "            pos_count += 6\n",
    "        \n",
    "        if fant_pts <= len(container.findAll('td', class_ = 'center')):\n",
    "            fant_pt = container.findAll('td', class_ = 'center')[fant_pts].get_text()\n",
    "            week_1.append(fant_pt)\n",
    "            fant_pts += 6\n",
    "    \n",
    "    return names, teams, positions, week_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_defense_stats(url):\n",
    "    \"\"\"\n",
    "    This function takes a url and passes it through requests.get and then uses BeautifulSoup to parse the html for \n",
    "    stats for a team's defense.\n",
    "    \n",
    "    Parameters:\n",
    "        url: website looking to scrape for information.\n",
    "        \n",
    "    Returns:\n",
    "        Completed dataframe with each team's total defensive stats season to date in the NFL.\n",
    "    \n",
    "    \"\"\"\n",
    "    html = requests.get(defense_url)\n",
    "    soup = BeautifulSoup(html.content, 'html.parser')\n",
    "    container = soup.find('tbody')\n",
    "    \n",
    "    yds_count = 0\n",
    "    att_count = 0\n",
    "    yds_p_att_count = 0\n",
    "    td_count = 0\n",
    "    \n",
    "    for i in range(len(container.findAll('span', class_ = 'hidden-xs-down'))):\n",
    "                \n",
    "        name = container.findAll('span', class_ = 'hidden-xs-down')[i].get_text()\n",
    "        \n",
    "        ttl_pts = container.findAll('td', {'data-title': 'PTS'})[i].get_text().replace('\\n', '').replace(' ', '')        \n",
    "        ttl_off = container.findAll('td', {'data-title': 'PLAYS'})[i].get_text().replace('\\n', '').replace(' ', '')\n",
    "        ttl_yds_p_play = container.findAll('td', {'data-title': 'YDS/PLAY'})[i].get_text().replace('\\n', '').replace(' ', '')\n",
    "        completions = container.findAll('td', {'data-title': 'COMP'})[i].get_text().replace('\\n', '').replace(' ', '')\n",
    "        yds_p_comp = container.findAll('td', {'data-title': 'YDS/COMP'})[i].get_text().replace('\\n', '').replace(' ', '')\n",
    "        rz_att = container.findAll('td', {'data-title': 'RZ ATT'})[i].get_text().replace('\\n', '').replace(' ', '')\n",
    "        rz_td = container.findAll('td', {'data-title': 'RZ TD'})[i].get_text().replace('\\n', '').replace(' ', '')\n",
    "        rz_perc = container.findAll('td', {'data-title': 'RZ %'})[i].get_text().replace('\\n', '').replace(' ', '')\n",
    "        turnovers = container.findAll('td', {'data-title': 'TOV'})[i].get_text().replace('\\n', '').replace(' ', '')\n",
    "        ints = container.findAll('td', {'data-title': 'INT'})[i].get_text().replace('\\n', '').replace(' ', '')\n",
    "        fumble = container.findAll('td', {'data-title': 'FUML'})[i].get_text().replace('\\n', '').replace(' ', '')\n",
    "        sacks = container.findAll('td', {'data-title': 'SACKS'})[i].get_text().replace('\\n', '').replace(' ', '')\n",
    "        \n",
    "        \n",
    "        if yds_count <= len(container.findAll('td', {'data-title': 'YDS'})):\n",
    "            ttl_yards = container.findAll('td', {'data-title': 'YDS'})[yds_count].get_text().replace('\\n', '').replace(' ', '')\n",
    "            yds_count += 1\n",
    "            rush_yds = container.findAll('td', {'data-title': 'YDS'})[yds_count].get_text().replace('\\n', '').replace(' ', '')\n",
    "            yds_count += 1\n",
    "            rec_yds = container.findAll('td', {'data-title': 'YDS'})[yds_count].get_text().replace('\\n', '').replace(' ', '')\n",
    "            yds_count += 1\n",
    "               \n",
    "        if att_count <= len(container.findAll('td', {'data-title': 'ATT'})):\n",
    "            rush_att = container.findAll('td', {'data-title': 'ATT'})[att_count].get_text().replace('\\n', '').replace(' ', '')\n",
    "            att_count += 1\n",
    "            rec_att = container.findAll('td', {'data-title': 'ATT'})[att_count].get_text().replace('\\n', '').replace(' ', '')\n",
    "            att_count += 1\n",
    "\n",
    "        if yds_p_att_count <= len(container.findAll('td', {'data-title': 'YDS/ATT'})):\n",
    "            rush_ypa = container.findAll('td', {'data-title': 'YDS/ATT'})[yds_p_att_count].get_text().replace('\\n', '').replace(' ', '')\n",
    "            yds_p_att_count += 1\n",
    "            rec_ypa = container.findAll('td', {'data-title': 'YDS/ATT'})[yds_p_att_count].get_text().replace('\\n', '').replace(' ', '')\n",
    "            yds_p_att_count += 1\n",
    "            \n",
    "        if td_count <= len(container.findAll('td', {'data-title': 'YDS/ATT'})):\n",
    "            rush_td = container.findAll('td', {'data-title': 'TD'})[td_count].get_text().replace('\\n', '').replace(' ', '')\n",
    "            td_count += 1\n",
    "            rec_td = container.findAll('td', {'data-title': 'TD'})[td_count].get_text().replace('\\n', '').replace(' ', '')\n",
    "            td_count += 1\n",
    "        \n",
    "        global defense_df\n",
    "        defense_df = defense_df.append({'Team': name, \n",
    "                                       'Ttl_Pts_Allowed': ttl_pts,\n",
    "                                       'Ttl_Offense_Plays_Allowed': ttl_off,\n",
    "                                       'Yds_p_Play': ttl_yds_p_play,\n",
    "                                       'Ttl_Yds': ttl_yards,\n",
    "                                       'Rushing_Att': rush_att,\n",
    "                                       'Rushing_Yds': rush_yds,\n",
    "                                       'Rushing_Yds_p_Att': rush_ypa,\n",
    "                                       'Rushing_TDs': rush_td,\n",
    "                                       'Passing_Att': rec_att,\n",
    "                                       'Passing_Yds_p_Att': rec_ypa,\n",
    "                                       'Completions': completions,\n",
    "                                       'Yds_p_Completion': yds_p_comp,\n",
    "                                       'Passing_Yds': rec_yds,\n",
    "                                       'Passing_TDs': rec_td,\n",
    "                                       'RZ_Att': rz_att,\n",
    "                                       'RZ_TD': rz_td,\n",
    "                                       'RZ_Percent': rz_perc,\n",
    "                                       'Ttl_Turnovers': turnovers,\n",
    "                                       'Interceptions': ints,\n",
    "                                       'Fumbles': fumble,\n",
    "                                       'Sacks': sacks}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting Data\n",
    "\n",
    "### Offense Player Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732e5ed99752430d8e508a45c634ca71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=461.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "offense_url = 'https://www.pro-football-reference.com/years/2020/fantasy.htm'\n",
    "get_offense(offense_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fantasy Pts by Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fantTTL_url = 'https://www.fantasypros.com/nfl/reports/leaders/?year=2020&start=1&end=' + str(week_no)\n",
    "weekTTL_fantasy['Player'], weekTTL_fantasy['Team'], weekTTL_fantasy['Position'], weekTTL_fantasy['TTL'] = get_lw_fantasy(fantTTL_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_url = 'https://www.fantasypros.com/nfl/reports/leaders/?year=2020&start=' + str(week_no) + '&end=' + str(week_no)\n",
    "week_fantasy['Player'], week_fantasy['Team'], week_fantasy['Position'], week_fantasy['Week_' + str(week_no)] = get_lw_fantasy(week_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging Ttl and Week Fantasy Pts DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fantPts = pd.merge(weekTTL_fantasy, week2_fantasy, 'left', on = 'Player')\n",
    "fantPts.drop(columns = ['Team_y', 'Position_y'], inplace = True)\n",
    "fantPts.rename(columns = {'Team_x': 'Team', 'Position_x': 'Position'}, inplace = True)\n",
    "fantPts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defense Stats by Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "defense_url = 'https://www.lineups.com/nfl/team-stats/defense'\n",
    "get_defense_stats(defense_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('player_stats')\n",
    "fantPts.to_pickle('fantasy_weeks')\n",
    "defense_df.to_pickle('defense_data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
